{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Text Data\n",
    "\n",
    "rpc = \"\"\"\n",
    "Curran International coated tube applications are globally known to prevent fouling in heat exchangers. For more than 25 years Curran’s proprietary applications of a low surface energy tube ID coatings have eliminated deposit nucleation down tube, reducing heat exchanger fouling and cleaning.\n",
    "\n",
    "Using highly functional immersion service coatings Curran applies a thin film, homogenous film down tube. The coated tube has a greatly reduced surface tension compared to uncoated steel and is inert to cooling water. Curran coatings are hydrophobic and create a high contact angle; immersion resistance to 365F gives the Curran coatings durability to periodic operating unit steam out.\n",
    "\n",
    "For cooling water, tube coating protects from deposit corrosion, and Curran delivers a “holiday free” application at 200 to 300 microns total thickness. Curran applies heat exchanger coating to shell & tube exchangers, tube bundles, U tube and plate and frame exchangers. Tube sheet coating – as part of the Curran tube coating application – protects tube ends, and the integrity of the roller expanded tube joint.\n",
    "\n",
    "Refinery and petrochemical clients have found exchanger tube ID coatings can immediately solve “bad actor” exchanger reliability where low flow, deposit accumulation limit the functional life of an asset. Curran heat exchanger internal coatings are specified as a value add for replacement exchangers, and are a lower cost option compared to an alloy upgrade.\n",
    "\n",
    "Curran has continued to develop its portfolio of thin film coating materials suited to a wide range of industrial services; cooling water, crude and hydrocarbon products, solvent and acid services. Sol Gel and hybrid materials are functional at < 25 microns total thickness. These ultra-thin applications are solutions for operation critical exchangers where crude and hydrocarbon services are primary causes of fouling in heat exchangers and can be applied to exchanger tube IDs, ODs and plate and frame exchangers.\n",
    "\n",
    "Curran can identify the best coating for operating unit conditions, and provide an application procedure and quality control report for surface prep, coating application, and inspection. The coated tube ID application is performed after the exchanger has been fabricated, the complete exchanger or tube bundle is coated, either at one of Curran’s global coating plants or in the field.\n",
    "\n",
    "Restoration of in-service, corroded exchangers is a practical repair strategy that Curran has years of successful project experience. It starts with “clean white metal” surface prep of exchanger, and remediation of soluble contaminants. Many of Curran tube coatings can be field applied, and force cured.\n",
    "\n",
    "The benefits of tube ID coating are known by refinery and petrochemical clients across the globe. Refinery bad actor bundles are likely poor performing exchangers due to the effects of fouling in heat exchangers. Equipment engineers specified heat exchanger coating to replace “in-kind” fabricated tube bundles using Curran tube ID coating; benefits were found in years of reduced maintenance, continuous operation run, and improved operating reliability.\n",
    "\n",
    "Curran is at the forefront of material and application technology development using advanced polymers and inorganic/hybrid coatings. Ultra thin (<25 micron) applications are solutions for operation critical exchangers where crude and hydrocarbon services are primary causes of fouling in heat exchangers. These new advanced technologies can be applied to exchanger tube IDs, ODs and plate and frame exchangers.\n",
    "\n",
    "All heat exchanger internal coating applications are subject to Curran quality control, and inspection observation and record points. We coat shell & tube exchanger bundles, air coolers, U tube and plate and frame exchangers; provide in-service exchange tube ID restoration; tube end coating, plate exchangers, OD tube coating; in-situ and field coating applications.\n",
    "\n",
    "Curran has mastered surface prep and application methods for coating in-service exchangers, this technique is used to restore exchangers for continued service. Curran can achieve NACE 1 white metal cleanliness of in-service exchanger tubes, and its application methods satisfy holiday spark testing requirements – even in pitted tubes. A homogeneous thin film coated tube mitigates fouling in heat exchangers and prevents tube ID corrosion.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Text Sources\n",
    "# From Curran Website > Services > Heat Exchanger Coating\n",
    "\n",
    "release_and_protective_coating = rpc\n",
    "\n",
    "exchanger_restoration_id_coating = \"\"\n",
    "\n",
    "corrosion_resistant_applications = \"\"\n",
    "\n",
    "foul_release_exchanger_coatings = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import English Language Class\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Instantiate English Class\n",
    "# Contains Pipeline,\n",
    "# Includes Language Specific Rules for Tokenizaion etc.\n",
    "nlp = English()\n",
    "\n",
    "# Create Documnet Object\n",
    "doc = nlp(rpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Curran International coated tube applications are globally known to prevent fouling in heat exchangers."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing Through Doc\n",
    "sent_span = doc[1:16]\n",
    "sent_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Curran International coated tube"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Slicing Through a Doc\n",
    "mini_span = doc[1:5]\n",
    "mini_span"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index [1, 2, 3, 4]\n",
      "Text ['Curran', 'International', 'coated', 'tube']\n",
      "Alphabet [True, True, True, True]\n",
      "Punct [False, False, False, False]\n",
      "Number [False, False, False, False]\n"
     ]
    }
   ],
   "source": [
    "# English Class Attributes\n",
    "print('Index', [token.i for token in mini_span])\n",
    "print('Text', [token.text for token in mini_span])\n",
    "print('Alphabet', [token.is_alpha for token in mini_span])\n",
    "print('Punct', [token.is_punct for token in mini_span])\n",
    "print('Number', [token.like_num for token in mini_span])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Models\n",
    "\n",
    "### en_core_web_sm\n",
    "en_core_web_sm is one of spaCy's pretrained model packages\n",
    "Stands For: English Core Web Small\n",
    "Enables spaCy to predict linguistic attributes in _context_.\n",
    "- Trained on labeled example text from the web.\n",
    "- Can be updated with more examples to fine-tune predictions.\n",
    "    - Part-of-speech tags\n",
    "    - Syntactic Dependencies\n",
    "    - Named Entities\n",
    "    - Binary Weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLP Library\n",
    "import spacy\n",
    "\n",
    "# Load Model Package -> Returns nlp Object\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(rpc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       " Curran International coated tube applications are globally known to prevent fouling in heat exchangers.,\n",
       " For more than 25 years Curran’s proprietary applications of a low surface energy tube ID coatings have eliminated deposit nucleation down tube, reducing heat exchanger fouling and cleaning.\n",
       " ]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Breaking Doc Up by Sentece\n",
    "# for i, sent in enumerate(doc.sents):\n",
    "#     print(i, sent)\n",
    "list(doc.sents)[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slicing Through Doc\n",
    "sent_span = doc[1:16]\n",
    "mini_span = doc[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT -- POS -- DEP --- HEAD\n",
      "Curran PROPN compound - International\n",
      "International PROPN nsubj - coated\n",
      "coated VERB amod - applications\n",
      "tube NOUN compound - applications\n",
      "applications NOUN nsubjpass - known\n",
      "are AUX auxpass - known\n",
      "globally ADV advmod - known\n",
      "known VERB ROOT - known\n",
      "to PART aux - prevent\n",
      "prevent VERB xcomp - known\n",
      "fouling NOUN xcomp - prevent\n",
      "in ADP prep - fouling\n",
      "heat NOUN compound - exchangers\n",
      "exchangers NOUN pobj - in\n",
      ". PUNCT punct - known\n"
     ]
    }
   ],
   "source": [
    "# Iterating Through Tokens\n",
    "print('TEXT -- POS -- DEP --- HEAD')\n",
    "for token in sent_span:\n",
    "    print(token.text, token.pos_, token.dep_, \"-\", token.head)\n",
    "\n",
    "# In spaCy, attributes that end with _ usually return -> a str\n",
    "# attributes witout underscore return -> an integer id value\n",
    "# Sytactic Head Token = Parent Token that a Word is Attached To"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "more than 25 years DATE\n",
      "Curran ORG\n",
      "Curran NORP\n",
      "Curran NORP\n",
      "200 to 300 CARDINAL\n",
      "shell & tube exchangers ORG\n",
      "Curran PRODUCT\n",
      "Sol Gel PERSON\n",
      "25 CARDINAL\n",
      "Curran PRODUCT\n",
      "Curran PERSON\n",
      "years DATE\n",
      "Curran NORP\n",
      "Curran NORP\n",
      "years DATE\n",
      "25 micron QUANTITY\n",
      "Curran NORP\n",
      "Curran ORG\n",
      "NACE 1 PRODUCT\n"
     ]
    }
   ],
   "source": [
    "# Predicting Named Entities\n",
    "\n",
    "# Iterate Over the Predicted Entities\n",
    "for ent in doc.ents:\n",
    "    # Print the Entity Text and It's Label\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nationalities or religious or political groups'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# spaCy .explain() Let's You See What Key Words Mean\n",
    "spacy.explain(\"NORP\") # hahaha - It thinks Curran is this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDK Why this Cell is Returning Errors\n",
    "\n",
    "# Rule-Based Matching\n",
    "# --- Better than Regex\n",
    "\n",
    "# # Import Matcher Class\n",
    "# from spacy.matcher import Matcher\n",
    "\n",
    "# # Initalize the Matcher with the Shared Vocab\n",
    "# matcher = Matcher(nlp.vocab, validate=True)\n",
    "\n",
    "# # Pattern is a List of Dictionaries\n",
    "# pattern = [{\"TEXT\": \"Curran\"}, {\"TEXT\", \"X\"}]\n",
    "# # Add the Pattern to the Matcher\n",
    "# matcher.add(\"CURRAN_PATTERN\", None, pattern)\n",
    "\n",
    "# # Call the Matcher on the Doc\n",
    "# matches = matcher(sent_span)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `vocab` - Shared Vocab and String Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4883023559053164773"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shared Vocab and String Store(1)\n",
    "\n",
    "# vocab -> stores data shared across multiple documents\n",
    "# - to save memory, spaCy encodes all strings to hash values\n",
    "# strings are only stored once in the StringStore via nlp.vocab.strings\n",
    "# string store -> lookup table in both directions\n",
    "\n",
    "Curran_hash = nlp.vocab.strings['Curran']\n",
    "Curran_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Curran'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Curran_string = nlp.vocab.strings[Curran_hash]\n",
    "Curran_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# will_return_error = nlp.vocab.strings[nlp.vocab.strings['Coffee']]\n",
    "# Because the\n",
    "# Word Coffee is not in our doc so it does not have a hash associated\n",
    "# with it yet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `lexeme` - Lexemes: Entries in the Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curran 4883023559053164773 True\n"
     ]
    }
   ],
   "source": [
    "lexeme = nlp.vocab['Curran']\n",
    "\n",
    "# Lexical Attributes\n",
    "print(lexeme.text, lexeme.orth, lexeme.is_alpha)\n",
    "\n",
    "# Lexemes Contain the Context-Independent Information about a Word\n",
    "# lexeme.orth is the word's hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lexeme.Lexeme at 0x7fd7c111c9c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexeme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Create a Doc Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello world!\n"
     ]
    }
   ],
   "source": [
    "# Import the Doc Class\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "# The Words and Spaces to Create the Doc From\n",
    "words = ['Hello', 'world', '!']\n",
    "spaces = [True, False, False]\n",
    "\n",
    "# Create a Doc Manually\n",
    "doc2 = Doc(nlp.vocab, words=words, spaces=spaces)\n",
    "\n",
    "print(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Hello world,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the Span Class\n",
    "from spacy.tokens import Span\n",
    "\n",
    "span_with_label = Span(doc2, 0, 2, label=\"GREETING\")\n",
    "\n",
    "doc2.ents = [span_with_label]\n",
    "doc2.ents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "- `Doc` and `Span` are very powerful and hold references and relationships of words and sentences\n",
    "- **Convert result to strings as late as possible**\n",
    "\n",
    "- Don't forget to pass in the shared `vocab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors and Semantic Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- spaCy can compare two objects and predict similarity\n",
    "- `Doc.similarity()`, `Token.similarity()`\n",
    "- Take another object and return a similarity score (0 to 1)\n",
    "- **Important:** needs a model that has word vectors included, for example:\n",
    "    - en_core_web_md (medium model)\n",
    "    - en_core_web_lg (large model)\n",
    "    - NOT en_core_web_sm (small model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import NLP Library\n",
    "import spacy\n",
    "\n",
    "# Medium or Large Model Pagages Include Word Vectors\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Load Model Package -> Returns nlp Object\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "doc = nlp(rpc)\n",
    "# Slicing Through Doc\n",
    "sent_span = doc[1:16]\n",
    "mini_span = doc[1:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applications homogenous\n"
     ]
    }
   ],
   "source": [
    "token_A = doc[5]\n",
    "token_B = doc[60]\n",
    "print(f\"token_A: {token_A}, token_B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17849906"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_A.similarity(token_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "span_A\n",
      "Curran International coated tube applications are globally known to prevent fouling in heat exchangers.\n",
      "span_B\n",
      "The coated tube has a greatly reduced surface tension compared to uncoated steel and is inert to cooling water.\n"
     ]
    }
   ],
   "source": [
    "span_A = sent_span\n",
    "span_B = doc[65:85]\n",
    "print(\"span_A\")\n",
    "print(span_A)\n",
    "print(\"span_B\")\n",
    "print(span_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8821999"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_A.similarity(span_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Vectors - How spaCy predicts similarity.\n",
    "\n",
    "- Similarity is determined using **word vectors**\n",
    "- Vectors = Multi-dimensional meaning representations of words.\n",
    "- Word Vectors are generated using an algorithm like Word2Vec and lots of text\n",
    "- Can be added to spaCy's statistical models\n",
    "- Default: cosine similarity, but can be adjusted\n",
    "- `Doc` and `Span` vectors default to average of token vectors\n",
    "- Short phrases are better than long documents with many irrelevant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.9668e-02  1.5119e-01 -3.9257e-01  4.6981e-02 -3.4844e-01 -2.7686e-01\n",
      " -7.3138e-01  2.5224e-01 -1.8603e-01 -5.5015e-01  2.0854e-01 -1.6892e-01\n",
      "  1.3877e-01 -2.0842e-01 -2.0709e-01  7.4798e-02  9.3722e-01  2.5331e+00\n",
      " -4.0550e-01  3.8841e-02 -3.0372e-01 -2.6431e-01  9.3540e-02 -2.3885e-02\n",
      "  9.2286e-02 -1.2340e-01 -1.9465e-01 -1.7334e-01 -3.4317e-01 -5.2152e-01\n",
      " -1.5143e-01  4.7240e-01 -2.4599e-01 -6.0763e-02  6.1894e-02 -3.5678e-01\n",
      "  4.1096e-01 -1.9635e-01  3.6910e-01  5.0845e-02  7.8336e-01 -8.0862e-02\n",
      " -1.8170e-01 -3.5227e-01 -2.1356e-01 -4.4844e-01 -2.5175e-01 -5.7316e-01\n",
      "  7.7689e-01 -1.2425e-01  3.2553e-01  1.1793e-01 -2.6172e-01 -4.5080e-01\n",
      " -8.0748e-02 -8.8334e-03  6.3997e-03  2.8156e-01 -2.6388e-01  3.4186e-01\n",
      " -1.1092e-01 -5.6916e-02 -3.2613e-01  2.4654e-01  9.7855e-02 -2.2802e-01\n",
      "  2.0652e-01  7.3356e-02 -3.7078e-01  1.6858e-01 -5.6588e-01  4.2366e-01\n",
      " -2.0123e-01  3.3987e-01 -5.4576e-01  1.8739e-01 -2.1602e-01  1.2351e-03\n",
      "  4.2705e-02 -3.0324e-01 -1.9245e-01  1.1415e-01 -6.0721e-01 -3.1484e-01\n",
      " -2.4671e-02 -4.2523e-01  1.0984e+00  1.4301e+00 -4.0284e-02  7.0835e-01\n",
      "  1.7605e-01  8.1954e-02  6.0347e-01  8.2972e-01  2.2581e-01  1.0909e-02\n",
      "  1.5417e-01 -5.3170e-01  3.1964e-01  1.7146e-01  6.2866e-01  4.8835e-01\n",
      " -1.3802e-01  1.1560e-01  6.0664e-02 -1.3710e+00 -1.4458e-01  8.9724e-03\n",
      "  2.5486e-01 -2.9906e-01 -2.8033e-01 -6.0317e-02  6.2359e-01 -2.6521e-01\n",
      " -2.3911e-01 -7.6553e-02 -3.7487e-01 -6.4229e-04  2.5968e-01  6.5621e-01\n",
      " -1.1556e-01  4.6156e-01 -9.1240e-02  3.2992e-01  6.0137e-01 -3.9060e-02\n",
      "  1.8463e-01 -4.0839e-01 -9.3639e-02 -1.7189e-01 -1.8885e-02 -2.2005e-01\n",
      " -4.1886e-02  4.8822e-01  1.0436e-01  4.6833e-01 -6.1366e-01 -7.4542e-02\n",
      " -3.3299e-01 -3.6212e-01 -1.1847e+00  1.1838e-01  4.0067e-01  2.8236e-01\n",
      "  8.6159e-02 -8.0849e-01 -2.2381e-01  3.1938e-01  5.4006e-01 -4.1881e-01\n",
      "  5.9054e-02 -6.3716e-01  3.0181e-03 -1.8801e-01 -5.3429e-01 -6.8432e-02\n",
      " -7.8725e-01  7.7412e-02  6.0640e-02  3.3354e-02  2.1700e-01 -3.2081e-01\n",
      "  2.6013e-02  2.5057e-01  2.1649e-01 -1.7794e-02  1.1062e-01 -4.8756e-01\n",
      " -2.0015e-01  3.6546e-01  7.2583e-01 -3.9913e-01 -9.3926e-01  5.2277e-03\n",
      " -4.3790e-01  2.2492e-01  4.0842e-01 -2.9024e-01  2.7666e-01 -5.5423e-02\n",
      "  3.6895e-01  3.6403e-01 -4.8019e-01 -6.8015e-01  9.0145e-02 -1.0411e-01\n",
      "  2.4391e-01  2.1173e-01 -4.0051e-01  1.6382e-01 -1.2021e-02 -5.4061e-01\n",
      "  2.4960e-01  6.2626e-02 -1.3886e-01  1.3865e-01  1.5803e-01  9.8494e-02\n",
      " -4.5805e-01 -6.7438e-01  4.6196e-02  3.1979e-02  2.0636e-01 -1.4052e-01\n",
      "  8.7742e-01  1.8077e-01 -5.4362e-02 -3.1841e-01  1.0444e-01  2.3343e-01\n",
      "  3.2743e-01  8.6099e-01 -2.1464e-01 -4.8802e-01  1.4624e-01  1.2433e-01\n",
      " -1.9130e-01 -3.2929e-01 -1.0447e-01 -3.7540e-02 -1.2115e+00  3.1128e-01\n",
      " -2.5045e-01  1.6195e-01 -2.4149e-02 -7.8514e-02 -3.4312e-01 -6.3536e-01\n",
      "  2.3079e-01  5.7999e-01 -1.6203e-01 -2.0995e-01  9.1290e-03 -2.0752e-01\n",
      "  7.8283e-01 -3.0846e-01 -2.7589e-02  1.2247e-01 -1.3241e-01  2.5316e-01\n",
      "  7.3200e-01 -2.0458e-02 -2.7916e-01 -3.3679e-01  3.8156e-02  1.0321e-01\n",
      " -2.8436e-01 -3.2854e-01  2.2561e-02 -4.7744e-02 -2.9224e-01 -1.3890e-01\n",
      "  2.0185e-01 -2.2278e-01  2.2928e-01  1.7896e-01  3.4642e-01  1.1471e-02\n",
      " -2.6913e-01  5.4908e-01  9.6065e-01 -2.7837e-01 -2.5137e-01 -1.5430e-01\n",
      "  4.5684e-02  1.3611e+00 -5.9149e-01 -3.9519e-01 -1.0514e-01  1.3322e-01\n",
      "  8.0183e-01 -4.2510e-02 -2.5101e-02  2.8088e-01 -6.0892e-02  6.5669e-01\n",
      "  3.8351e-01  2.0140e-01 -8.1553e-01 -1.3917e-01  9.1197e-02  4.1604e-01\n",
      "  4.0530e-01 -6.7331e-01 -9.0362e-02  2.8441e-02 -9.5314e-02 -3.6893e-01\n",
      " -3.0885e-01  3.3172e-01 -1.5454e-01 -8.8018e-02 -1.1093e-01 -1.5149e-01\n",
      " -3.5884e-01  5.6181e-01  3.1499e-01 -1.7102e-01 -3.9852e-02  5.9416e-01]\n"
     ]
    }
   ],
   "source": [
    "# What a word vector looks like:\n",
    "\n",
    "doc3 = nlp(\"I have a banana.\")\n",
    "\n",
    "# Access the vector via the token.vector attribute\n",
    "print(doc[3].vector)\n",
    "\n",
    "# Damn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_love = nlp(\"I love cats.\")\n",
    "doc_hate = nlp(\"I hate cats.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9564359513862217"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# But it's not always perfect....\n",
    "doc_love.similarity(doc_hate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity depends on the application context\n",
    "- `similarity` is useful for many applications: recommendation systems, flaggin duplicates etc.\n",
    "- There's no objective definition of \"similarity\"\n",
    "- Depends on the context and what application needs to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Models and Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
